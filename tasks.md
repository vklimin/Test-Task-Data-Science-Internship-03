# Тестовые задания

* [Задание 1](#задание-1)
* [Задание 2](#задание-2)

## CoreML

### Задание 1

Мы обучили модель классификации и получили ROC-AUC-метрику со значением 0,2 (метрика посчитана на тестовом). Что это значит?

Выберите один вариант из списка:

* ❌ Модель переобучилась
* ✅ Модель обучалась на неверных данных таргета
* ❌ Модель обучилась хорошо
* ❌ Модель обучилась на несбалансированных данных

---

**Объяснение:**

ROC-AUC = 0,2 — это очень низкое значение (ниже случайного угадывания, которое соответствует 0,5). Это означает, что модель работает хуже шанса. Чаще всего такое происходит, если метки классов (таргет) были перепутаны при обучении — например, все «1» приняты за «0» и наоборот. В этом случае модель может быть по сути "инвертированной", и её предсказания можно легко исправить, просто поменяв знак вероятностей.

---

### Задание 2

Допустим, мы обучили модель бинарной классификации с precision = 80% на выборке из 1000 примеров и предсказали позитивный класс в 150 случаях. Какая полнота у нашей модели, если всего позитивных примеров  в выборке — 240?

Выберите один вариант из списка:

* ❌ 75%
* ❌ 24%
* ✅ 50%
* ❌ 62,5%

---

**Объяснение:**

#### Шаг 1: Вспомним определения метрик

**Precision (Точность)** — это доля действительно положительных объектов среди тех, что модель пометила как положительные.

Формула точности:  
Precision = TP / (TP + FP)

Где:
- TP (True Positive) — истинно положительные: модель сказала "да", и правда "да"
- FP (False Positive) — ложно положительные: модель сказала "да", но на самом деле "нет"

**Recall (Полнота)** — это доля правильно предсказанных положительных примеров среди всех реальных положительных.

Формула полноты:  
Recall = TP / (TP + FN)

Где:
- FN (False Negative) — ложно отрицательные: модель сказала "нет", но на самом деле "да"

---

#### Шаг 2: Найдём количество истинно положительных (TP)

Из условия:
- Precision = 80% = 0.8
- Количество предсказаний "положительный класс" = 150 → это сумма TP + FP

Подставим в формулу точности:  
Precision = TP / (TP + FP) = TP / 150 = 0.8

Значит:  
TP = 0.8 × 150 = 120

Модель **верно** определила **120** положительных примеров.

---

#### Шаг 3: Найдём полноту (Recall)

Общее число реальных положительных примеров = 240 → это TP + FN

У нас TP = 120, значит:  
FN = 240 - 120 = 120

Теперь вычислим полноту:  
Recall = TP / (TP + FN) = 120 / (120 + 120) = 120 / 240 = 0.5 = **50%**

---
